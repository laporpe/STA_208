{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Functions import Cleaning_Functions\n",
    "from sklearn import model_selection, linear_model, neighbors, preprocessing, metrics, ensemble\n",
    "\n",
    "fun = Cleaning_Functions()\n",
    "\n",
    "clean = pd.read_csv(\"../data/clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_data(df):\n",
    "        \"\"\"\n",
    "        Input: a dataset\n",
    "        action: returns numeric column values scaled by mean and standard deviation\n",
    "        \"\"\"\n",
    "        numeric_data = df.select_dtypes(include=['float64', 'int64'])\n",
    "        for i in numeric_data.columns:\n",
    "            df[i] = (df[i] - df[i].mean())/df[i].std()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data = fun.delete_id_columns(clean) #1\n",
    "market_data, pred_market = fun.drop_response_rows_with_NAs(market_data, \"Market_Orientation\", \"PPI_Likelihood\") #2\n",
    "market_data = fun.replace_NAN_with_na(market_data) #3\n",
    "market_data = fun.entry_to_lowercase(market_data) #4\n",
    "market_data = fun.remove_underscores_spaces(market_data) #5\n",
    "market_data = fun.convert_to_categorical(market_data) #6\n",
    "market_data = fun.impute_data(market_data)\n",
    "market_data = standarize_data(market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ana's fuc\n",
    "def get_dummyXs_y(df, y_var):\n",
    "    \n",
    "    y = df[y_var]\n",
    "    X  = df.drop(y_var, axis = 1)\n",
    "    X_cat = X.select_dtypes(include = [\"category\", \"O\"])\n",
    "    X_num = X.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    X_cat_dummy = pd.get_dummies(X_cat)\n",
    "    newX = pd.concat([X_num, X_cat_dummy], axis = 1)\n",
    "    \n",
    "    return newX, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_dummyXs_y(market_data, \"Market_Orientation\")\n",
    "X_tr, X_te, y_tr, y_te = model_selection.train_test_split(X,y, test_size = 0.3, random_state = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, X_tr, X_te, y_tr, y_te):\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    pred = clf.predict(X_te)\n",
    "    mse = metrics.mean_squared_error(y_te, pred)\n",
    "    \n",
    "    return \"MSE: {} \".format(mse)\n",
    "\n",
    "\n",
    "\n",
    "def tune_parameters(X_train, y_train, clf, param_dict, cv=5):\n",
    "    \n",
    "   \n",
    "    \n",
    "    best_model = model_selection.GridSearchCV(clf, param_dict, cv=cv, scoring = \"neg_mean_squared_error\", n_jobs =-1, verbose=3)\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Parameters: {} \\n Training MSE: {} \\n Parameter Index: {}\".format(best_model.best_params_,best_model.best_score_,best_model.best_index_) ) # best is alpha = 0\n",
    "\n",
    "\n",
    "    #uses gridsearch, prints best parameters, best model, its MSE on the training set\n",
    "    #returns classifer\n",
    "    \n",
    "    return clf\n",
    "\n",
    "test_mse_market = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market Orientation\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 50, 'max_features': 'auto', 'n_estimators': 200} \n",
      " Training MSE: -0.010516094751742087 \n",
      " Parameter Index: 26\n"
     ]
    }
   ],
   "source": [
    "forest_model = ensemble.RandomForestRegressor()\n",
    "fit_predict(forest_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20, 50], 'max_features':[\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "best_forest = tune_parameters( X_tr, y_tr,forest_model, parameters)\n",
    "\n",
    "forest_pred = best_forest.predict(X_te)\n",
    "forest_test_mse_market = metrics.mean_squared_error(y_te, forest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.004644118607085156\n"
     ]
    }
   ],
   "source": [
    "test_mse.append(\"Random Forrest Test MSE:{}\".format(forest_test_mse))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, forest_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_livestock_prod_consumed_USD_PPP_pHH_Yr    0.427205\n",
       "farm_income_USD_PPP_pHH_Yr                      0.303100\n",
       "value_crop_consumed_USD_PPP_pHH_Yr              0.127582\n",
       "total_income_USD_PPP_pHH_Yr                     0.126198\n",
       "value_farm_produce_USD_PPP_pHH_Yr               0.004343\n",
       "                                                  ...   \n",
       "crop_name_1_broadbeans                          0.000000\n",
       "crop_name_1_achiote                             0.000000\n",
       "crop_name_1_watermelon                          0.000000\n",
       "crop_name_1_zucchini                            0.000000\n",
       "crop_name_1_chickpeas                           0.000000\n",
       "Length: 159, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "forest_importances = pd.Series(best_forest.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "forest_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'n_estimators': 250} \n",
      " Training MSE: -0.012467946363262442 \n",
      " Parameter Index: 3\n",
      "Test MSE: 0.021677865365120983\n"
     ]
    }
   ],
   "source": [
    "XG_model = ensemble.GradientBoostingRegressor()\n",
    "fit_predict(XG_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20,50]}\n",
    "\n",
    "best_XG = tune_parameters( X_tr, y_tr,XG_model, parameters)\n",
    "\n",
    "XG_pred = best_XG.predict(X_te)\n",
    "XG_test_mse = metrics.mean_squared_error(y_te, XG_pred)\n",
    "\n",
    "\n",
    "test_mse_market.append(\"XGBoost Test MSE:{}\".format(XG_test_mse))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, XG_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_livestock_prod_consumed_USD_PPP_pHH_Yr    0.449191\n",
       "farm_income_USD_PPP_pHH_Yr                      0.322268\n",
       "value_crop_consumed_USD_PPP_pHH_Yr              0.131396\n",
       "total_income_USD_PPP_pHH_Yr                     0.068298\n",
       "value_farm_produce_USD_PPP_pHH_Yr               0.018361\n",
       "                                                  ...   \n",
       "crop_name_1_yam                                 0.000000\n",
       "crop_name_1_wheat                               0.000000\n",
       "crop_name_1_watermelon                          0.000000\n",
       "crop_name_1_tomato                              0.000000\n",
       "crop_name_1_pigeonpea                           0.000000\n",
       "Length: 159, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "XG_importances = pd.Series(best_XG.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "XG_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPI_Likelihood\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPI_data = fun.delete_id_columns(clean) #1\n",
    "PPI_data, pred_PPI = fun.drop_response_rows_with_NAs(PPI_data, \"PPI_Likelihood\", \"Market_Orientation\") #2\n",
    "PPI_data = fun.replace_NAN_with_na(PPI_data) #3\n",
    "PPI_data = fun.entry_to_lowercase(PPI_data) #4\n",
    "PPI_data = fun.remove_underscores_spaces(PPI_data) #5\n",
    "PPI_data = fun.convert_to_categorical(PPI_data) #6\n",
    "PPI_data = fun.impute_data(PPI_data)\n",
    "PPI_data = standarize_data(PPI_data)\n",
    "\n",
    "\n",
    "X, y = get_dummyXs_y(PPI_data, \"PPI_Likelihood\")\n",
    "X_tr, X_te, y_tr, y_te = model_selection.train_test_split(X,y, test_size = 0.3, random_state = 50)\n",
    "\n",
    "test_mse_ppi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'n_estimators': 200} \n",
      " Training MSE: -0.38538118741894906 \n",
      " Parameter Index: 6\n",
      "Test MSE: 0.3931938260734791\n"
     ]
    }
   ],
   "source": [
    "forest_model = ensemble.RandomForestRegressor()\n",
    "fit_predict(forest_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20, 50]}\n",
    "\n",
    "best_forest = tune_parameters( X_tr, y_tr,forest_model, parameters)\n",
    "\n",
    "forest_pred = best_forest.predict(X_te)\n",
    "forest_test_mse_ppi = metrics.mean_squared_error(y_te, forest_pred)\n",
    "\n",
    "test_mse_ppi.append(\"Random Forrest Test MSE:{}\".format(forest_test_mse_ppi))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, forest_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country_mali                0.163262\n",
       "Country_zambia              0.142931\n",
       "LivestockHoldings           0.056198\n",
       "continent_africa            0.052077\n",
       "HHsizemembers               0.044168\n",
       "                              ...   \n",
       "crop_name_1_custardapple    0.000000\n",
       "crop_name_1_coriander       0.000000\n",
       "crop_name_1_peas            0.000000\n",
       "crop_name_1_lemons          0.000000\n",
       "crop_name_1_tobacco         0.000000\n",
       "Length: 154, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "forest_importances = pd.Series(best_forest.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "forest_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'n_estimators': 120} \n",
      " Training MSE: -0.3860526893646002 \n",
      " Parameter Index: 1\n",
      "Test MSE: 0.4070801718035054\n"
     ]
    }
   ],
   "source": [
    "XG_model = ensemble.GradientBoostingRegressor()\n",
    "fit_predict(XG_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 20)), 'max_depth': [10,20,50]}\n",
    "\n",
    "best_XG = tune_parameters( X_tr, y_tr,XG_model, parameters)\n",
    "\n",
    "XG_pred = best_XG.predict(X_te)\n",
    "XG_test_mse = metrics.mean_squared_error(y_te, XG_pred)\n",
    "\n",
    "test_mse_ppi.append(\"XGBoost Test MSE:{}\".format(XG_test_mse))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, XG_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country_mali                0.250837\n",
       "Country_zambia              0.215757\n",
       "continent_africa            0.073566\n",
       "HHsizemembers               0.066270\n",
       "Country_malawi              0.059080\n",
       "                              ...   \n",
       "crop_name_1_sugarcane       0.000000\n",
       "crop_name_1_sunflower       0.000000\n",
       "crop_name_1_sweetpotato     0.000000\n",
       "crop_name_1_tea             0.000000\n",
       "crop_name_1_passionfruit    0.000000\n",
       "Length: 154, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XG_importances = pd.Series(best_XG.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "XG_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Specific PPI Likeilhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
