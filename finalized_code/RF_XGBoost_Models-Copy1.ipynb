{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Functions import Cleaning_Functions\n",
    "from sklearn import model_selection, linear_model, neighbors, preprocessing, metrics, ensemble\n",
    "\n",
    "fun = Cleaning_Functions()\n",
    "\n",
    "clean = pd.read_csv(\"../data/clean.csv\")\n",
    "clean  = clean.drop(\"continent\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_data(df):\n",
    "        \"\"\"\n",
    "        Input: a dataset\n",
    "        action: returns numeric column values scaled by mean and standard deviation\n",
    "        \"\"\"\n",
    "        numeric_data = df.select_dtypes(include=['float64', 'int64'])\n",
    "        for i in numeric_data.columns:\n",
    "            df[i] = (df[i] - df[i].mean())/df[i].std()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data = fun.delete_id_columns(clean) #1\n",
    "market_data, pred_market = fun.drop_response_rows_with_NAs(market_data, \"Market_Orientation\", \"PPI_Likelihood\") #2\n",
    "market_data = fun.replace_NAN_with_na(market_data) #3\n",
    "market_data = fun.entry_to_lowercase(market_data) #4\n",
    "market_data = fun.remove_underscores_spaces(market_data) #5\n",
    "market_data = fun.convert_to_categorical(market_data) #6\n",
    "market_data = fun.impute_data(market_data)\n",
    "market_data = standarize_data(market_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ana's fuc\n",
    "def get_dummyXs_y(df, y_var):\n",
    "    \n",
    "    y = df[y_var]\n",
    "    X  = df.drop(y_var, axis = 1)\n",
    "    X_cat = X.select_dtypes(include = [\"category\", \"O\"])\n",
    "    X_num = X.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    X_cat_dummy = pd.get_dummies(X_cat)\n",
    "    newX = pd.concat([X_num, X_cat_dummy], axis = 1)\n",
    "    \n",
    "    return newX, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_dummyXs_y(market_data, \"Market_Orientation\")\n",
    "X_tr, X_te, y_tr, y_te = model_selection.train_test_split(X,y, test_size = 0.3, random_state = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, X_tr, X_te, y_tr, y_te):\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    pred = clf.predict(X_te)\n",
    "    mse = metrics.mean_squared_error(y_te, pred)\n",
    "    \n",
    "    return \"MSE: {} \".format(mse)\n",
    "\n",
    "\n",
    "\n",
    "def tune_parameters(X_train, y_train, clf, param_dict, cv=5):\n",
    "    \n",
    "   \n",
    "    \n",
    "    best_model = model_selection.GridSearchCV(clf, param_dict, cv=cv, scoring = \"neg_mean_squared_error\", n_jobs =-1, verbose=3)\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Parameters: {} \\n Training MSE: {} \\n Parameter Index: {}\".format(best_model.best_params_,best_model.best_score_,best_model.best_index_) ) # best is alpha = 0\n",
    "\n",
    "\n",
    "    #uses gridsearch, prints best parameters, best model, its MSE on the training set\n",
    "    #returns classifer\n",
    "    \n",
    "    return clf\n",
    "\n",
    "test_mse_market = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market Orientation\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 50, 'max_features': 'auto', 'n_estimators': 250} \n",
      " Training MSE: -0.014588005751682892 \n",
      " Parameter Index: 27\n"
     ]
    }
   ],
   "source": [
    "forest_model = ensemble.RandomForestRegressor()\n",
    "fit_predict(forest_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20, 50], 'max_features':[\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "best_forest = tune_parameters( X_tr, y_tr,forest_model, parameters)\n",
    "\n",
    "forest_pred = best_forest.predict(X_te)\n",
    "forest_test_mse_market = metrics.mean_squared_error(y_te, forest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_mse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-24d0e16dd75d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forrest Test MSE:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest_test_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test MSE: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforest_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_mse' is not defined"
     ]
    }
   ],
   "source": [
    "test_mse.append(\"Random Forrest Test MSE:{}\".format(forest_test_mse))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, forest_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_importances = pd.Series(best_forest.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "forest_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model = ensemble.GradientBoostingRegressor()\n",
    "fit_predict(XG_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20,50]}\n",
    "\n",
    "best_XG = tune_parameters( X_tr, y_tr,XG_model, parameters)\n",
    "\n",
    "XG_pred = best_XG.predict(X_te)\n",
    "XG_test_mse = metrics.mean_squared_error(y_te, XG_pred)\n",
    "\n",
    "\n",
    "test_mse_market.append(\"XGBoost Test MSE:{}\".format(XG_test_mse))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, XG_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XG_importances = pd.Series(best_XG.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "XG_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPI_Likelihood\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPI_data = fun.delete_id_columns(clean) #1\n",
    "PPI_data, pred_PPI = fun.drop_response_rows_with_NAs(PPI_data, \"PPI_Likelihood\", \"Market_Orientation\") #2\n",
    "PPI_data = fun.replace_NAN_with_na(PPI_data) #3\n",
    "PPI_data = fun.entry_to_lowercase(PPI_data) #4\n",
    "PPI_data = fun.remove_underscores_spaces(PPI_data) #5\n",
    "PPI_data = fun.convert_to_categorical(PPI_data) #6\n",
    "PPI_data = fun.impute_data(PPI_data)\n",
    "PPI_data = standarize_data(PPI_data)\n",
    "\n",
    "\n",
    "X, y = get_dummyXs_y(PPI_data, \"PPI_Likelihood\")\n",
    "X_tr, X_te, y_tr, y_te = model_selection.train_test_split(X,y, test_size = 0.3, random_state = 50)\n",
    "\n",
    "test_mse_ppi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = ensemble.RandomForestRegressor()\n",
    "fit_predict(forest_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20, 50]}\n",
    "\n",
    "best_forest = tune_parameters( X_tr, y_tr,forest_model, parameters)\n",
    "\n",
    "forest_pred = best_forest.predict(X_te)\n",
    "forest_test_mse_ppi = metrics.mean_squared_error(y_te, forest_pred)\n",
    "\n",
    "test_mse_ppi.append(\"Random Forrest Test MSE:{}\".format(forest_test_mse_ppi))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, forest_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_importances = pd.Series(best_forest.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "forest_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model = ensemble.GradientBoostingRegressor()\n",
    "fit_predict(XG_model, X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "\n",
    "parameters = dict()\n",
    "parameters = {'n_estimators':(np.arange(100, 300, 20)), 'max_depth': [10,20,50]}\n",
    "\n",
    "best_XG = tune_parameters( X_tr, y_tr,XG_model, parameters)\n",
    "\n",
    "XG_pred = best_XG.predict(X_te)\n",
    "XG_test_mse = metrics.mean_squared_error(y_te, XG_pred)\n",
    "\n",
    "test_mse_ppi.append(\"XGBoost Test MSE:{}\".format(XG_test_mse))\n",
    "\n",
    "print(\"Test MSE: {}\".format(metrics.mean_squared_error(y_te, XG_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XG_importances = pd.Series(best_XG.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "XG_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Specific PPI Likeilhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces a dictionary of country specific dataframes\n",
    "country_dict={}\n",
    "for country in PPI_data[\"Country\"].values.unique():\n",
    "    new_df = PPI_data[PPI_data[\"Country\"].values  == country]\n",
    "    country_dict[country] = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper func\n",
    "def country_model(country, y, clf, parameter_dict):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    country: str, country name as appears in dataframe\n",
    "    y: str, column name of response\n",
    "    clf: scikitlearn clf, the scikit learn model to train \n",
    "    parameter_dict: dict, dictionary of model parameters\n",
    "    \n",
    "    OUTPUT\n",
    "    country: str, country name as appears in dataframe\n",
    "    clf: trained best model\n",
    "    mse: test mse for this model\n",
    "    index: the list of dummy varaible columns for that country\n",
    "    \"\"\"\n",
    "    X,y = get_dummyXs_y(country_dict[country], y)\n",
    "    X_tr,X_te,y_tr,y_te = model_selection.train_test_split(X,y, test_size=0.3, random_state=50)\n",
    "    \n",
    "    index = X.columns\n",
    "    fit_predict(clf, X_tr,X_te,y_tr,y_te)\n",
    "    \n",
    "    best_clf = tune_parameters(X_tr, y_tr, clf, parameter_dict)\n",
    "    \n",
    "    best_pred = best_clf.predict(X_te)\n",
    "    mse = metrics.mean_squared_error(y_te, best_pred)\n",
    "    print(best_clf.feature_importances_.sort())\n",
    "    print(\"\\n \\n {} \\n Test MSE: {}\".format(country, mse))\n",
    "    \n",
    "    return country, best_clf.feature_importances_, mse, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict[\"ghana\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest_model = ensemble.RandomForestRegressor()\n",
    "parameters= {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20, 50]}\n",
    "\n",
    "#\n",
    "#name, ghana_forrest, ghana_mse, index = country_model(country_dict[\"ghana\"], \"PPI_Likelihood\",forest_model,parameters)\n",
    "#for key in country_dict:\n",
    "\n",
    "\n",
    "country_results= {}\n",
    "for country in PPI_data[\"Country\"].values.unique():\n",
    "    country_results[country] =country_model(country,\n",
    "                          \"PPI_Likelihood\",\n",
    "                          forest_model,\n",
    "                          parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_feature = {}\n",
    "for country in country_results:\n",
    "    country_feature[country] = pd.Series(country_results[country][1], \n",
    "                                      index=country_results[country][3].values).sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_feature[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_feature(country, ax1):\n",
    "    country_feature[country][1:10].plot(kind=\"bar\", \n",
    "                                   title = \"Most Important Features: {}\".format(country), \n",
    "                                   ylabel = \"Importance Metric\",\n",
    "                                   xlabel = \"Features\", ax=ax1)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for country in country_feature:\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5), \n",
    "                             sharex=False)\n",
    "plot_country_feature(\"tanzania\", ax1=ax1)\n",
    "plot_country_feature(\"guatemala\", ax1=ax2)\n",
    "plot_country_feature(\"honduras\", ax1=ax3)\n",
    "plot_country_feature(\"elsalvador\", ax1=ax4)\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5), \n",
    "                             sharex=False)\n",
    "plot_country_feature(\"mali\", ax1=ax1)\n",
    "plot_country_feature(\"burkinafaso\", ax1=ax2)\n",
    "plot_country_feature(\"malawi\", ax1=ax3)\n",
    "plot_country_feature(\"ethiopia\", ax1=ax4)\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5), \n",
    "                             sharex=False)\n",
    "plot_country_feature(\"india\", ax1=ax1)\n",
    "plot_country_feature(\"cambodia\", ax1=ax2)\n",
    "plot_country_feature(\"vietnam\", ax1=ax3)\n",
    "plot_country_feature(\"kenya\", ax1=ax4)\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5), \n",
    "                             sharex=False)\n",
    "plot_country_feature(\"zambia\", ax1=ax1)\n",
    "plot_country_feature(\"ghana\", ax1=ax2)\n",
    "plot_country_feature(\"uganda\", ax1=ax3)\n",
    "plot_country_feature(\"peru\", ax1=ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Continent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv(\"../data/clean.csv\")\n",
    "clean  = clean.drop(\"Country\", axis =1)\n",
    "\n",
    "PPI_data = fun.delete_id_columns(clean) #1\n",
    "PPI_data, pred_PPI = fun.drop_response_rows_with_NAs(PPI_data, \"PPI_Likelihood\", \"Market_Orientation\") #2\n",
    "PPI_data = fun.replace_NAN_with_na(PPI_data) #3\n",
    "PPI_data = fun.entry_to_lowercase(PPI_data) #4\n",
    "PPI_data = fun.remove_underscores_spaces(PPI_data) #5\n",
    "PPI_data = fun.convert_to_categorical(PPI_data) #6\n",
    "PPI_data = fun.impute_data(PPI_data)\n",
    "PPI_data = standarize_data(PPI_data)\n",
    "\n",
    "\n",
    "X, y = get_dummyXs_y(PPI_data, \"PPI_Likelihood\")\n",
    "X_tr, X_te, y_tr, y_te = model_selection.train_test_split(X,y, test_size = 0.3, random_state = 50)\n",
    "\n",
    "test_mse_ppi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces a dictionary of country specific dataframes\n",
    "continent_dict={}\n",
    "for continent in PPI_data[\"continent\"].values.unique():\n",
    "    new_df = PPI_data[PPI_data[\"continent\"].values  == continent]\n",
    "    continent_dict[continent] = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continent_model(continent, y, clf, parameter_dict):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    continent: str, continent name as appears in dataframe\n",
    "    y: str, column name of response\n",
    "    clf: scikitlearn clf, the scikit learn model to train \n",
    "    parameter_dict: dict, dictionary of model parameters\n",
    "    \n",
    "    OUTPUT\n",
    "    continent: str, continent name as appears in dataframe\n",
    "    clf: trained best model\n",
    "    mse: test mse for this model\n",
    "    index: the list of dummy varaible columns for that country\n",
    "    \"\"\"\n",
    "    X,y = get_dummyXs_y(continent_dict[continent], y)\n",
    "    X_tr,X_te,y_tr,y_te = model_selection.train_test_split(X,y, test_size=0.3, random_state=50)\n",
    "    \n",
    "    index = X.columns\n",
    "    fit_predict(clf, X_tr,X_te,y_tr,y_te)\n",
    "    \n",
    "    best_clf = tune_parameters(X_tr, y_tr, clf, parameter_dict)\n",
    "    \n",
    "    best_pred = best_clf.predict(X_te)\n",
    "    mse = metrics.mean_squared_error(y_te, best_pred)\n",
    "    print(best_clf.feature_importances_.sort())\n",
    "    print(\"\\n \\n {} \\n Test MSE: {}\".format(continent, mse))\n",
    "    \n",
    "    return continent, best_clf.feature_importances_, mse, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = ensemble.RandomForestRegressor()\n",
    "parameters= {'n_estimators':(np.arange(100, 300, 50)), 'max_depth': [10,20, 50]}\n",
    "\n",
    "#\n",
    "#name, ghana_forrest, ghana_mse, index = country_model(country_dict[\"ghana\"], \"PPI_Likelihood\",forest_model,parameters)\n",
    "#for key in country_dict:\n",
    "\n",
    "\n",
    "continent_results= {}\n",
    "for continent in PPI_data[\"continent\"].values.unique():\n",
    "    continent_results[continent] =continent_model(continent,\n",
    "                          \"PPI_Likelihood\",\n",
    "                          forest_model,\n",
    "                          parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_feature = {}\n",
    "for continent in continent_results:\n",
    "    continent_feature[continent] = pd.Series(continent_results[continent][1], \n",
    "                                      index=continent_results[continent][3].values).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_continent_feature(continent, ax1):\n",
    "    continent_feature[continent][1:10].plot(kind=\"bar\", \n",
    "                                   title = \"Most Important Features: {}\".format(continent), \n",
    "                                   ylabel = \"Importance Metric\",\n",
    "                                   xlabel = \"Features\",\n",
    "                                            ax=ax1)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5), \n",
    "                             sharex=False)\n",
    "plot_continent_feature(\"africa\", ax1=ax1)\n",
    "plot_continent_feature(\"centralamerica\", ax1=ax2)\n",
    "plot_continent_feature(\"asia\", ax1=ax3)\n",
    "plot_continent_feature(\"southamerica\", ax1=ax4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
